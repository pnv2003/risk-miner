{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b9b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Snorkel if not already installed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Import Snorkel modules for labeling and denoising\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LabelingFunction\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling.model.baselines import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9729a",
   "metadata": {},
   "source": [
    "# Jira Project Risk Labeling\n",
    "\n",
    "This notebook uses Snorkel to label projects based on schedule and quality risk indicators. The notebook includes options to customize the labeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1101a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: Use Label Model = False\n",
      "Quantile Threshold = 0.7, Probability Threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Configuration Settings\n",
    "\n",
    "# Whether to use the label model for denoising (True) or just use majority voting (False)\n",
    "USE_LABEL_MODEL = False  # Set to False to use only majority voting\n",
    "# Note: Label model only works with 3+ labeling functions\n",
    "\n",
    "# Define constants for Snorkel labels\n",
    "ABSTAIN = -1\n",
    "LOW_RISK = 0\n",
    "HIGH_RISK = 1\n",
    "\n",
    "# Threshold settings\n",
    "QUANTILE_THRESHOLD = 0.7  # 70th percentile for feature thresholds\n",
    "PROBABILITY_THRESHOLD = 0.5  # Threshold for converting probabilities to binary labels\n",
    "\n",
    "print(f\"Configuration: Use Label Model = {USE_LABEL_MODEL}\")\n",
    "print(f\"Quantile Threshold = {QUANTILE_THRESHOLD}, Probability Threshold = {PROBABILITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfaa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (492, 45)\n",
      "Test data shape: (124, 45)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "project_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "project_key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "project_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "project_category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_reopened",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "average_lifespan",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_workspan",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_change_density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_reassignment_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_description_edit_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_author_churn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_fix_version_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_time_estimate_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_resolution_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_status_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_priority_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "average_issue_type_change_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_changes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_assignees",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_reporters",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_members",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_issues",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_duplicate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_won't_fix",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_other",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_fixed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_invalid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_incomplete",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_auto_closed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_workaround",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_resolution_feedback",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_status_to_do",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_status_in_progress",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_status_other",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_status_done",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_priority_high",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_priority_low",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_priority_medium",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_priority_other",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_issue_type_other",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_issue_type_feature",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_issue_type_improvement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_issue_type_bug",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_issue_type_task",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_high_priority_bugs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8b6b2871-adbf-46db-a841-da66e6f3a28c",
       "rows": [
        [
         "0",
         "12316921",
         "CONTINUUM",
         "Continuum",
         "Build, Release, & Project Management",
         "135",
         "183.38867404703092",
         "718.0957961199457",
         "344.1069020682358",
         "0.06278415412204129",
         "0.00467510429151102",
         "0.8593609341020584",
         "0.17312276205974106",
         "0.0029483426471828447",
         "0.07931911688108974",
         "0.08490632383436215",
         "0.001407810457552478",
         "0.0010241087131532655",
         "26269",
         "48",
         "634",
         "643",
         "2704",
         "189",
         "197",
         "410",
         "1685",
         "146",
         "77",
         "0",
         "0",
         "0",
         "410",
         "0",
         "0",
         "2294",
         "193",
         "516",
         "1995",
         "0",
         "1",
         "297",
         "639",
         "1533",
         "234",
         "161"
        ],
        [
         "1",
         "12310732",
         "JSPWIKI",
         "JSPWiki",
         "Web Frameworks & UI",
         "95",
         "322.9024676580825",
         "1607.4972038786104",
         "72.10238462620883",
         "0.053574092980947716",
         "0.024021552532986268",
         "0.8871268656716418",
         "0.11791098923749704",
         "0.0003031716417910448",
         "0.1764035829698364",
         "0.3003677139150301",
         "0.013453984656808266",
         "0.0029090144411972768",
         "6021",
         "19",
         "297",
         "299",
         "1072",
         "36",
         "69",
         "153",
         "706",
         "103",
         "5",
         "0",
         "0",
         "0",
         "151",
         "2",
         "0",
         "919",
         "48",
         "567",
         "457",
         "0",
         "0",
         "74",
         "285",
         "593",
         "120",
         "43"
        ],
        [
         "2",
         "12310493",
         "TRANSACTION",
         "Commons Transaction",
         "Libraries & Utilities (Commons & Core)",
         "2",
         "242.37609953703708",
         "502.27762511022917",
         "7.014969643977119",
         "0.06295523259808974",
         "0.01058201058201058",
         "0.6904761904761905",
         "0.042424242424242434",
         "0.0",
         "0.06831709956709955",
         "0.10610999450285163",
         "0.0047619047619047615",
         "0.0",
         "191",
         "3",
         "28",
         "29",
         "42",
         "0",
         "3",
         "21",
         "14",
         "3",
         "1",
         "0",
         "0",
         "0",
         "20",
         "1",
         "0",
         "21",
         "4",
         "10",
         "28",
         "0",
         "0",
         "6",
         "10",
         "25",
         "1",
         "4"
        ],
        [
         "3",
         "12323721",
         "MWRAPPER",
         "Maven Wrapper",
         "Build, Release, & Project Management",
         "15",
         "155.0864690320573",
         "248.86816805260673",
         "80.23991761469415",
         "0.049586435523522064",
         "0.03753844726258823",
         "0.4904458598726114",
         "0.05163755955560699",
         "0.0",
         "0.07168697831117235",
         "0.07229914289599358",
         "0.007342533616418967",
         "0.0011976699874789046",
         "977",
         "13",
         "74",
         "74",
         "148",
         "4",
         "5",
         "38",
         "102",
         "7",
         "0",
         "0",
         "0",
         "1",
         "37",
         "1",
         "0",
         "119",
         "6",
         "28",
         "122",
         "1",
         "0",
         "12",
         "39",
         "80",
         "26",
         "5"
        ],
        [
         "4",
         "12310740",
         "HTTPDRAFT",
         "Labs WebArch draft-fielding-http (Retired)",
         "Incubator & Retired/Dormant Projects",
         "0",
         "13.550386284722224",
         "38.347902485246244",
         "8.97571941656499",
         "0.11283438783438784",
         "0.0",
         "0.9615384615384616",
         "0.025074925074925074",
         "0.0",
         "0.02629592629592629",
         "0.02629592629592629",
         "0.0",
         "0.0",
         "1491",
         "2",
         "3",
         "3",
         "95",
         "2",
         "0",
         "134",
         "46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "134",
         "0",
         "0",
         "48",
         "0",
         "2",
         "6",
         "174",
         "0",
         "0",
         "70",
         "112",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>project_key</th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_category</th>\n",
       "      <th>total_reopened</th>\n",
       "      <th>average_lifespan</th>\n",
       "      <th>average_workspan</th>\n",
       "      <th>average_change_density</th>\n",
       "      <th>average_reassignment_rate</th>\n",
       "      <th>average_description_edit_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>num_priority_high</th>\n",
       "      <th>num_priority_low</th>\n",
       "      <th>num_priority_medium</th>\n",
       "      <th>num_priority_other</th>\n",
       "      <th>num_issue_type_other</th>\n",
       "      <th>num_issue_type_feature</th>\n",
       "      <th>num_issue_type_improvement</th>\n",
       "      <th>num_issue_type_bug</th>\n",
       "      <th>num_issue_type_task</th>\n",
       "      <th>num_high_priority_bugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12316921</td>\n",
       "      <td>CONTINUUM</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>Build, Release, &amp; Project Management</td>\n",
       "      <td>135</td>\n",
       "      <td>183.388674</td>\n",
       "      <td>718.095796</td>\n",
       "      <td>344.106902</td>\n",
       "      <td>0.062784</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>516</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>639</td>\n",
       "      <td>1533</td>\n",
       "      <td>234</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12310732</td>\n",
       "      <td>JSPWIKI</td>\n",
       "      <td>JSPWiki</td>\n",
       "      <td>Web Frameworks &amp; UI</td>\n",
       "      <td>95</td>\n",
       "      <td>322.902468</td>\n",
       "      <td>1607.497204</td>\n",
       "      <td>72.102385</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>567</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>285</td>\n",
       "      <td>593</td>\n",
       "      <td>120</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12310493</td>\n",
       "      <td>TRANSACTION</td>\n",
       "      <td>Commons Transaction</td>\n",
       "      <td>Libraries &amp; Utilities (Commons &amp; Core)</td>\n",
       "      <td>2</td>\n",
       "      <td>242.376100</td>\n",
       "      <td>502.277625</td>\n",
       "      <td>7.014970</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12323721</td>\n",
       "      <td>MWRAPPER</td>\n",
       "      <td>Maven Wrapper</td>\n",
       "      <td>Build, Release, &amp; Project Management</td>\n",
       "      <td>15</td>\n",
       "      <td>155.086469</td>\n",
       "      <td>248.868168</td>\n",
       "      <td>80.239918</td>\n",
       "      <td>0.049586</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12310740</td>\n",
       "      <td>HTTPDRAFT</td>\n",
       "      <td>Labs WebArch draft-fielding-http (Retired)</td>\n",
       "      <td>Incubator &amp; Retired/Dormant Projects</td>\n",
       "      <td>0</td>\n",
       "      <td>13.550386</td>\n",
       "      <td>38.347902</td>\n",
       "      <td>8.975719</td>\n",
       "      <td>0.112834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id  project_key                                project_name  \\\n",
       "0    12316921    CONTINUUM                                   Continuum   \n",
       "1    12310732      JSPWIKI                                     JSPWiki   \n",
       "2    12310493  TRANSACTION                         Commons Transaction   \n",
       "3    12323721     MWRAPPER                               Maven Wrapper   \n",
       "4    12310740    HTTPDRAFT  Labs WebArch draft-fielding-http (Retired)   \n",
       "\n",
       "                         project_category  total_reopened  average_lifespan  \\\n",
       "0    Build, Release, & Project Management             135        183.388674   \n",
       "1                     Web Frameworks & UI              95        322.902468   \n",
       "2  Libraries & Utilities (Commons & Core)               2        242.376100   \n",
       "3    Build, Release, & Project Management              15        155.086469   \n",
       "4    Incubator & Retired/Dormant Projects               0         13.550386   \n",
       "\n",
       "   average_workspan  average_change_density  average_reassignment_rate  \\\n",
       "0        718.095796              344.106902                   0.062784   \n",
       "1       1607.497204               72.102385                   0.053574   \n",
       "2        502.277625                7.014970                   0.062955   \n",
       "3        248.868168               80.239918                   0.049586   \n",
       "4         38.347902                8.975719                   0.112834   \n",
       "\n",
       "   average_description_edit_rate  ...  num_priority_high  num_priority_low  \\\n",
       "0                       0.004675  ...                193               516   \n",
       "1                       0.024022  ...                 48               567   \n",
       "2                       0.010582  ...                  4                10   \n",
       "3                       0.037538  ...                  6                28   \n",
       "4                       0.000000  ...                  0                 2   \n",
       "\n",
       "   num_priority_medium  num_priority_other  num_issue_type_other  \\\n",
       "0                 1995                   0                     1   \n",
       "1                  457                   0                     0   \n",
       "2                   28                   0                     0   \n",
       "3                  122                   1                     0   \n",
       "4                    6                 174                     0   \n",
       "\n",
       "   num_issue_type_feature  num_issue_type_improvement  num_issue_type_bug  \\\n",
       "0                     297                         639                1533   \n",
       "1                      74                         285                 593   \n",
       "2                       6                          10                  25   \n",
       "3                      12                          39                  80   \n",
       "4                       0                          70                 112   \n",
       "\n",
       "   num_issue_type_task  num_high_priority_bugs  \n",
       "0                  234                     161  \n",
       "1                  120                      43  \n",
       "2                    1                       4  \n",
       "3                   26                       5  \n",
       "4                    0                       0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_csv('./apache/train.csv')\n",
    "print(f\"Training data shape: {df_train.shape}\")\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv('./apache/test.csv')\n",
    "print(f\"Test data shape: {df_test.shape}\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faf28ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep import preprocess_data\n",
    "\n",
    "# Preprocess both training and test data\n",
    "df_train = preprocess_data(df_train)\n",
    "df_test = preprocess_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d5ece3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 8827.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling Functions Coverage (Training Data):\n",
      "lf_high_incomplete_ratio: 1.000\n",
      "lf_combined_indicators: 1.000\n",
      "\n",
      "Using majority voting for schedule risk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 10439.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schedule Risk Distribution (Majority Vote) - Training Data:\n",
      "0    0.699187\n",
      "1    0.300813\n",
      "Name: schedule_risk, dtype: float64\n",
      "\n",
      "Schedule Risk Distribution (Majority Vote) - Training Data:\n",
      "0    0.699187\n",
      "1    0.300813\n",
      "Name: schedule_risk_majority_vote, dtype: float64\n",
      "\n",
      "Schedule Risk Distribution (Majority Vote) - Test Data:\n",
      "0    0.75\n",
      "1    0.25\n",
      "Name: schedule_risk, dtype: float64\n",
      "\n",
      "Schedule Risk Distribution (Majority Vote) - Test Data:\n",
      "0    0.75\n",
      "1    0.25\n",
      "Name: schedule_risk_majority_vote, dtype: float64\n",
      "\n",
      "Labeling Function Summary (Training Data):\n",
      "   j         Labeling Function Polarity  Coverage  Overlaps  Conflicts\n",
      "0  0  lf_high_incomplete_ratio        +       1.0       1.0        0.0\n",
      "1  1    lf_combined_indicators        -       1.0       1.0        0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from upsetplot import plot as upset_plot\n",
    "# from upsetplot import from_indicators\n",
    "import numpy as np\n",
    "\n",
    "# Define schedule risk indicators (features)\n",
    "schedule_risk_indicators = [\n",
    "    # 'average_lifespan',\n",
    "    # 'average_reassignment_rate', \n",
    "    'incomplete_ratio',\n",
    "]\n",
    "\n",
    "# Calculate z-scores for each indicator to standardize them - ON TRAIN DATA ONLY\n",
    "for col in schedule_risk_indicators:\n",
    "    # Calculate mean and std from training data only\n",
    "    train_mean = df_train[col].mean()\n",
    "    train_std = df_train[col].std()\n",
    "    \n",
    "    # Apply standardization to both train and test using training statistics\n",
    "    df_train[f'z_{col}'] = (df_train[col] - train_mean) / train_std\n",
    "    df_test[f'z_{col}'] = (df_test[col] - train_mean) / train_std\n",
    "\n",
    "# Use the quantile threshold from configuration\n",
    "quantile_threshold = QUANTILE_THRESHOLD\n",
    "\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# Dynamically create labeling functions for each schedule risk indicator\n",
    "def make_high_indicator_lf(indicator, threshold_value):\n",
    "    @labeling_function(name=f\"lf_high_{indicator}\")\n",
    "    def lf(x):\n",
    "        return HIGH_RISK if x[indicator] > threshold_value else LOW_RISK\n",
    "    return lf\n",
    "\n",
    "# Create labeling functions using thresholds from training data only\n",
    "schedule_lfs = []\n",
    "for ind in schedule_risk_indicators:\n",
    "    threshold = df_train[ind].quantile(quantile_threshold)\n",
    "    schedule_lfs.append(make_high_indicator_lf(ind, threshold))\n",
    "\n",
    "# Create combined indicator LF using thresholds from training data\n",
    "z_cols = [f'z_{col}' for col in schedule_risk_indicators]\n",
    "combined_threshold = df_train[z_cols].mean(axis=1).quantile(quantile_threshold)\n",
    "\n",
    "@labeling_function(name=\"lf_combined_indicators\")\n",
    "def lf_combined_indicators(x):\n",
    "    z_score_mean = np.mean([x[f'z_{col}'] for col in schedule_risk_indicators])\n",
    "    return HIGH_RISK if z_score_mean > combined_threshold else LOW_RISK\n",
    "\n",
    "schedule_lfs.append(lf_combined_indicators)\n",
    "\n",
    "# Apply labeling functions to the training dataframe\n",
    "lf_applier = PandasLFApplier(schedule_lfs)\n",
    "L_schedule_train = lf_applier.apply(df_train)\n",
    "\n",
    "# Print the coverage for each LF on training data\n",
    "print(\"Labeling Functions Coverage (Training Data):\")\n",
    "for i, lf in enumerate(schedule_lfs):\n",
    "    cov = (L_schedule_train[:, i] != ABSTAIN).mean()\n",
    "    print(f\"{lf.name}: {cov:.3f}\")\n",
    "\n",
    "# Initialize majority voter for comparison\n",
    "mv = MajorityLabelVoter()\n",
    "df_train['schedule_risk_majority_vote'] = mv.predict(L_schedule_train)\n",
    "\n",
    "# Conditional label model training based on configuration\n",
    "if USE_LABEL_MODEL:\n",
    "    # Train the label model to denoise and combine the labeling functions\n",
    "    print(\"\\nTraining label model for schedule risk...\")\n",
    "    label_model = LabelModel(cardinality=2, verbose=True)\n",
    "    label_model.fit(L_schedule_train, n_epochs=500, log_freq=100, seed=42)\n",
    "    \n",
    "    # Apply the trained model to get the denoised labels for training data\n",
    "    schedule_risk_proba_train = label_model.predict_proba(L_schedule_train)\n",
    "    df_train['schedule_risk_score'] = schedule_risk_proba_train[:, 1]  # Probability of HIGH_RISK\n",
    "    \n",
    "    # Use the probability threshold from configuration\n",
    "    df_train['schedule_risk'] = (df_train['schedule_risk_score'] >= PROBABILITY_THRESHOLD).astype(int)\n",
    "else:\n",
    "    # Use majority voting for labels if not using label model\n",
    "    print(\"\\nUsing majority voting for schedule risk...\")\n",
    "    df_train['schedule_risk'] = df_train['schedule_risk_majority_vote']\n",
    "    \n",
    "    # For consistency, create a risk score column (binary 0 or 1)\n",
    "    df_train['schedule_risk_score'] = df_train['schedule_risk'].astype(float)\n",
    "\n",
    "# Now apply the same labeling functions to the test data\n",
    "L_schedule_test = lf_applier.apply(df_test)\n",
    "\n",
    "# For test data, apply the same approach as training based on configuration\n",
    "df_test['schedule_risk_majority_vote'] = mv.predict(L_schedule_test)\n",
    "\n",
    "if USE_LABEL_MODEL:\n",
    "    # Apply the trained model to test data\n",
    "    schedule_risk_proba_test = label_model.predict_proba(L_schedule_test)\n",
    "    df_test['schedule_risk_score'] = schedule_risk_proba_test[:, 1]  # Probability of HIGH_RISK\n",
    "    df_test['schedule_risk'] = (df_test['schedule_risk_score'] >= PROBABILITY_THRESHOLD).astype(int)\n",
    "else:\n",
    "    # Use majority voting for test data too if not using label model\n",
    "    df_test['schedule_risk'] = df_test['schedule_risk_majority_vote']\n",
    "    df_test['schedule_risk_score'] = df_test['schedule_risk'].astype(float)\n",
    "\n",
    "# Display the risk distribution for training data\n",
    "labeling_method = \"Denoised Labels\" if USE_LABEL_MODEL else \"Majority Vote\"\n",
    "print(f\"\\nSchedule Risk Distribution ({labeling_method}) - Training Data:\")\n",
    "print(df_train['schedule_risk'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSchedule Risk Distribution (Majority Vote) - Training Data:\")\n",
    "print(df_train['schedule_risk_majority_vote'].value_counts(normalize=True))\n",
    "\n",
    "# Display the risk distribution for test data\n",
    "print(f\"\\nSchedule Risk Distribution ({labeling_method}) - Test Data:\")\n",
    "print(df_test['schedule_risk'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSchedule Risk Distribution (Majority Vote) - Test Data:\")\n",
    "print(df_test['schedule_risk_majority_vote'].value_counts(normalize=True))\n",
    "\n",
    "# Analyze agreement between labeling functions on training data\n",
    "def lf_summary(L, lfs):\n",
    "    \"\"\"Returns a summary of labeling function statistics\"\"\"\n",
    "    d = {\n",
    "        \"j\": list(range(len(lfs))),\n",
    "        \"Labeling Function\": [lf.name for lf in lfs],\n",
    "        \"Polarity\": [\"+\" if lf.name.startswith('lf_high') else \"-\" for lf in lfs],\n",
    "        \"Coverage\": [(L[:, i] != ABSTAIN).mean() for i in range(L.shape[1])],\n",
    "        \"Overlaps\": [\n",
    "            sum((L[:, i] != ABSTAIN) & (L[:, j] != ABSTAIN)) / len(L) \n",
    "            for i, j in zip(range(L.shape[1]), range(-1, L.shape[1]-1))\n",
    "        ],\n",
    "        \"Conflicts\": [\n",
    "            sum((L[:, i] != ABSTAIN) & (L[:, j] != ABSTAIN) & (L[:, i] != L[:, j])) / len(L) \n",
    "            for i, j in zip(range(L.shape[1]), range(-1, L.shape[1]-1))\n",
    "        ],\n",
    "    }\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "# Print summary statistics for labeling functions on training data\n",
    "print(\"\\nLabeling Function Summary (Training Data):\")\n",
    "print(lf_summary(L_schedule_train, schedule_lfs))\n",
    "\n",
    "# Transform Snorkel matrix to binary indicators for training data\n",
    "df_lf_flags = pd.DataFrame()\n",
    "lf_names = [lf.name for lf in schedule_lfs]\n",
    "for i, name in enumerate(lf_names):\n",
    "    df_lf_flags[name] = (L_schedule_train[:, i] == HIGH_RISK)\n",
    "\n",
    "# dump df_fl_flags to a CSV file for further analysis\n",
    "df_lf_flags.to_csv(\"./apache/schedule_risk_lf_flags.csv\", index=False)\n",
    "\n",
    "# upset_data = from_indicators(df_lf_flags)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# upset_plot(\n",
    "#     upset_data,\n",
    "#     sort_by='cardinality',\n",
    "#     show_counts=True,\n",
    "#     subset_size='count'\n",
    "# )\n",
    "# plt.suptitle(\"Overlap of Schedule Risk Labeling Functions\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6696f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/492 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 27292.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling Functions Coverage (Training Data):\n",
      "lf_high_high_priority_bug_ratio: 1.000\n",
      "\n",
      "Using majority voting for quality risk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 13070.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality Risk Distribution (Majority Vote) - Training Data:\n",
      "0    0.699187\n",
      "1    0.300813\n",
      "Name: quality_risk, dtype: float64\n",
      "\n",
      "Quality Risk Distribution (Majority Vote) - Training Data:\n",
      "0    0.699187\n",
      "1    0.300813\n",
      "Name: quality_risk_majority_vote, dtype: float64\n",
      "\n",
      "Quality Risk Distribution (Majority Vote) - Test Data:\n",
      "0    0.725806\n",
      "1    0.274194\n",
      "Name: quality_risk, dtype: float64\n",
      "\n",
      "Quality Risk Distribution (Majority Vote) - Test Data:\n",
      "0    0.725806\n",
      "1    0.274194\n",
      "Name: quality_risk_majority_vote, dtype: float64\n",
      "\n",
      "Labeling Function Summary (Training Data):\n",
      "   j                Labeling Function Polarity  Coverage  Overlaps  Conflicts\n",
      "0  0  lf_high_high_priority_bug_ratio        +       1.0       1.0        0.0\n"
     ]
    }
   ],
   "source": [
    "# Define quality risk indicators\n",
    "quality_risk_indicators = [\n",
    "    # 'num_issue_type_bug_ratio',\n",
    "    'high_priority_bug_ratio',\n",
    "    # 'reopen_ratio',\n",
    "    # 'bug_to_development_ratio',\n",
    "    # 'inverse_fix_rate',\n",
    "]\n",
    "\n",
    "# Check if we have sufficient indicators\n",
    "if len(quality_risk_indicators) == 0:\n",
    "    print(\"No quality risk indicators available in the dataset\")\n",
    "else:\n",
    "    # Calculate z-scores for each indicator based on training data only\n",
    "    for col in quality_risk_indicators:\n",
    "        # Calculate mean and std from training data\n",
    "        train_mean = df_train[col].mean()\n",
    "        train_std = df_train[col].std()\n",
    "        \n",
    "        # Apply to both train and test using training statistics\n",
    "        df_train[f'z_{col}'] = (df_train[col] - train_mean) / train_std\n",
    "        df_test[f'z_{col}'] = (df_test[col] - train_mean) / train_std\n",
    "\n",
    "    # Use the quantile threshold from configuration\n",
    "    quantile_threshold = QUANTILE_THRESHOLD\n",
    "\n",
    "    # Define labeling functions for quality risk using thresholds from training data\n",
    "    def make_high_indicator_lf(indicator, threshold_value):\n",
    "        @labeling_function(name=f\"lf_high_{indicator}\")\n",
    "        def lf(x):\n",
    "            return HIGH_RISK if x[indicator] > threshold_value else LOW_RISK\n",
    "        return lf\n",
    "\n",
    "    # Create LFs for each indicator using thresholds from training data\n",
    "    quality_lfs = []\n",
    "    for col in quality_risk_indicators:\n",
    "        threshold = df_train[col].quantile(quantile_threshold)\n",
    "        quality_lfs.append(make_high_indicator_lf(col, threshold))\n",
    "\n",
    "    # Add a combined z-score LF if there are at least 2 indicators\n",
    "    if len(quality_risk_indicators) > 1:\n",
    "        # Calculate threshold from training data\n",
    "        z_cols = [f'z_{col}' for col in quality_risk_indicators]\n",
    "        combined_threshold = df_train[z_cols].mean(axis=1).quantile(quantile_threshold)\n",
    "        \n",
    "        @labeling_function()\n",
    "        def lf_combined_quality(x):\n",
    "            z_score_mean = np.mean([x[f'z_{col}'] for col in quality_risk_indicators])\n",
    "            return HIGH_RISK if z_score_mean > combined_threshold else LOW_RISK\n",
    "        \n",
    "        quality_lfs.append(lf_combined_quality)\n",
    "\n",
    "    # Apply labeling functions to the training dataframe\n",
    "    lf_applier = PandasLFApplier(quality_lfs)\n",
    "    L_quality_train = lf_applier.apply(df_train)\n",
    "\n",
    "    # Print the coverage for each LF on training data\n",
    "    print(\"Labeling Functions Coverage (Training Data):\")\n",
    "    for i, lf in enumerate(quality_lfs):\n",
    "        cov = (L_quality_train[:, i] != ABSTAIN).mean()\n",
    "        print(f\"{lf.name}: {cov:.3f}\")\n",
    "\n",
    "    # Initialize majority voter for comparison\n",
    "    mv = MajorityLabelVoter()\n",
    "    df_train['quality_risk_majority_vote'] = mv.predict(L_quality_train)\n",
    "\n",
    "    # Conditional label model training based on configuration\n",
    "    if USE_LABEL_MODEL:\n",
    "        # Train the label model to denoise and combine the labeling functions\n",
    "        print(\"\\nTraining label model for quality risk...\")\n",
    "        label_model = LabelModel(cardinality=2, verbose=True)\n",
    "        label_model.fit(L_quality_train, n_epochs=500, log_freq=100, seed=42)\n",
    "        \n",
    "        # Apply the trained model to get the denoised labels for training data\n",
    "        quality_risk_proba_train = label_model.predict_proba(L_quality_train)\n",
    "        df_train['quality_risk_score'] = quality_risk_proba_train[:, 1]  # Probability of HIGH_RISK\n",
    "        \n",
    "        # Use the probability threshold from configuration\n",
    "        df_train['quality_risk'] = (df_train['quality_risk_score'] >= PROBABILITY_THRESHOLD).astype(int)\n",
    "    else:\n",
    "        # Use majority voting for labels if not using label model\n",
    "        print(\"\\nUsing majority voting for quality risk...\")\n",
    "        df_train['quality_risk'] = df_train['quality_risk_majority_vote']\n",
    "        \n",
    "        # For consistency, create a risk score column (binary 0 or 1)\n",
    "        df_train['quality_risk_score'] = df_train['quality_risk'].astype(float)\n",
    "\n",
    "    # Now apply the same labeling functions to the test data\n",
    "    L_quality_test = lf_applier.apply(df_test)\n",
    "\n",
    "    # For test data, apply the same approach as training based on configuration\n",
    "    df_test['quality_risk_majority_vote'] = mv.predict(L_quality_test)\n",
    "\n",
    "    if USE_LABEL_MODEL:\n",
    "        # Apply the trained model to test data\n",
    "        quality_risk_proba_test = label_model.predict_proba(L_quality_test)\n",
    "        df_test['quality_risk_score'] = quality_risk_proba_test[:, 1]  # Probability of HIGH_RISK\n",
    "        df_test['quality_risk'] = (df_test['quality_risk_score'] >= PROBABILITY_THRESHOLD).astype(int)\n",
    "    else:\n",
    "        # Use majority voting for test data too if not using label model\n",
    "        df_test['quality_risk'] = df_test['quality_risk_majority_vote']\n",
    "        df_test['quality_risk_score'] = df_test['quality_risk'].astype(float)\n",
    "\n",
    "    # Display the risk distribution for training data\n",
    "    labeling_method = \"Denoised Labels\" if USE_LABEL_MODEL else \"Majority Vote\"\n",
    "    print(f\"\\nQuality Risk Distribution ({labeling_method}) - Training Data:\")\n",
    "    print(df_train['quality_risk'].value_counts(normalize=True))\n",
    "\n",
    "    print(\"\\nQuality Risk Distribution (Majority Vote) - Training Data:\")\n",
    "    print(df_train['quality_risk_majority_vote'].value_counts(normalize=True))\n",
    "\n",
    "    # Display the risk distribution for test data\n",
    "    print(f\"\\nQuality Risk Distribution ({labeling_method}) - Test Data:\")\n",
    "    print(df_test['quality_risk'].value_counts(normalize=True))\n",
    "\n",
    "    print(\"\\nQuality Risk Distribution (Majority Vote) - Test Data:\")\n",
    "    print(df_test['quality_risk_majority_vote'].value_counts(normalize=True))\n",
    "\n",
    "    # Analyze agreement between labeling functions on training data\n",
    "    print(\"\\nLabeling Function Summary (Training Data):\")\n",
    "    print(lf_summary(L_quality_train, quality_lfs))\n",
    "\n",
    "    # Transform Snorkel matrix to binary indicators for training data\n",
    "    df_lf_flags = pd.DataFrame()\n",
    "    lf_names = [lf.name for lf in quality_lfs]\n",
    "    for i, name in enumerate(lf_names):\n",
    "        df_lf_flags[name] = (L_quality_train[:, i] == HIGH_RISK)\n",
    "\n",
    "    # dump df_fl_flags to a CSV file for further analysis\n",
    "    df_lf_flags.to_csv(\"./apache/quality_risk_lf_flags.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dff1ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Category Distribution (Training Data):\n",
      "Low Risk              229\n",
      "Schedule Risk Only    115\n",
      "Quality Risk Only     115\n",
      "High Risk              33\n",
      "Name: risk_category, dtype: int64\n",
      "\n",
      "Risk Category Distribution (Test Data):\n",
      "Low Risk              65\n",
      "Quality Risk Only     28\n",
      "Schedule Risk Only    25\n",
      "High Risk              6\n",
      "Name: risk_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate combined risk for both training and test sets\n",
    "df_train['combined_risk'] = df_train.apply(lambda x: \n",
    "                                f\"S{x['schedule_risk']}Q{x['quality_risk']}\", \n",
    "                                axis=1)\n",
    "\n",
    "df_test['combined_risk'] = df_test.apply(lambda x: \n",
    "                                f\"S{x['schedule_risk']}Q{x['quality_risk']}\", \n",
    "                                axis=1)\n",
    "\n",
    "risk_mapping = {\n",
    "    'S0Q0': 'Low Risk', \n",
    "    'S0Q1': 'Quality Risk Only', \n",
    "    'S1Q0': 'Schedule Risk Only',\n",
    "    'S1Q1': 'High Risk'\n",
    "}\n",
    "\n",
    "df_train['risk_category'] = df_train['combined_risk'].map(risk_mapping)\n",
    "df_test['risk_category'] = df_test['combined_risk'].map(risk_mapping)\n",
    "\n",
    "# Display risk distribution for training data\n",
    "print(\"Risk Category Distribution (Training Data):\")\n",
    "print(df_train['risk_category'].value_counts())\n",
    "\n",
    "# Display risk distribution for test data\n",
    "print(\"\\nRisk Category Distribution (Test Data):\")\n",
    "print(df_test['risk_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c399f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk labels saved to './apache/train_project_risk_labels.csv' and './apache/test_project_risk_labels.csv'\n",
      "Combined risk labels saved to './apache/all_project_risk_labels.csv'\n"
     ]
    }
   ],
   "source": [
    "# Extract risk labels for both training and test datasets\n",
    "train_risk_labels_df = df_train[[\n",
    "    'project_id', \n",
    "    'schedule_risk', 'schedule_risk_score', 'schedule_risk_majority_vote',\n",
    "    'quality_risk', 'quality_risk_score', 'quality_risk_majority_vote',\n",
    "    'combined_risk', 'risk_category',\n",
    "]]\n",
    "\n",
    "test_risk_labels_df = df_test[[\n",
    "    'project_id', \n",
    "    'schedule_risk', 'schedule_risk_score', 'schedule_risk_majority_vote',\n",
    "    'quality_risk', 'quality_risk_score', 'quality_risk_majority_vote',\n",
    "    'combined_risk', 'risk_category',\n",
    "]]\n",
    "\n",
    "# Save to CSV\n",
    "train_risk_labels_df.to_csv(\"./apache/train_project_risk_labels.csv\", index=False)\n",
    "test_risk_labels_df.to_csv(\"./apache/test_project_risk_labels.csv\", index=False)\n",
    "print(\"Risk labels saved to './apache/train_project_risk_labels.csv' and './apache/test_project_risk_labels.csv'\")\n",
    "\n",
    "# You can also save the combined data if needed\n",
    "all_risk_labels_df = pd.concat([\n",
    "    train_risk_labels_df.assign(dataset='train'), \n",
    "    test_risk_labels_df.assign(dataset='test')\n",
    "])\n",
    "all_risk_labels_df.to_csv(\"./apache/all_project_risk_labels.csv\", index=False)\n",
    "print(\"Combined risk labels saved to './apache/all_project_risk_labels.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b92e5",
   "metadata": {},
   "source": [
    "# How to Use Different Labeling Methods\n",
    "\n",
    "To change the labeling method:\n",
    "\n",
    "1. Go to the \"Configuration Settings\" cell near the top of this notebook\n",
    "2. Set `USE_LABEL_MODEL = True` to use the Snorkel Label Model for denoising\n",
    "3. Set `USE_LABEL_MODEL = False` to use only majority voting\n",
    "4. Re-run all cells to apply the change\n",
    "\n",
    "The label model helps to denoise the weak supervision signals when labeling functions may conflict, while majority voting is a simpler approach that works well when labeling functions are reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
